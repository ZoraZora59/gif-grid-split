"""
ç²¾çµè¡¨è½¬ GIF Web åº”ç”¨
Flask åç«¯ API
"""

import os
import sys
import uuid
import time
import shutil
import threading
import json
from datetime import datetime, timedelta
from flask import Flask, request, jsonify, send_file, render_template
from werkzeug.utils import secure_filename
from io import BytesIO

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core import analyze_spritesheet, slice_spritesheet_to_frames, create_gif_from_frames
from core.slicer import slice_spritesheet
from web.idea_generator import generate_idea_plan

app = Flask(__name__)

# ============================================
# é…ç½®
# ============================================

# æ•°æ®å­˜å‚¨ç›®å½•ï¼ˆå¯é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰
DATA_FOLDER = os.environ.get('DATA_FOLDER', os.path.join(os.path.dirname(__file__), 'data'))

# å­ç›®å½•
ORIGINALS_FOLDER = os.path.join(DATA_FOLDER, 'originals')    # åŸå›¾
FRAMES_FOLDER = os.path.join(DATA_FOLDER, 'frames')          # åˆ‡åˆ†åçš„å¸§
GIFS_FOLDER = os.path.join(DATA_FOLDER, 'gifs')              # ç”Ÿæˆçš„ GIF
TEMP_FOLDER = os.path.join(DATA_FOLDER, 'temp')              # ä¸´æ—¶æ–‡ä»¶

# æ–‡ä»¶é™åˆ¶
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif', 'bmp', 'webp'}
MAX_CONTENT_LENGTH = 16 * 1024 * 1024  # 16MB

# æ–‡ä»¶ä¿ç•™æ—¶é—´ï¼ˆç§’ï¼‰
FILE_RETENTION_DAYS = int(os.environ.get('FILE_RETENTION_DAYS', 30))
FILE_MAX_AGE = FILE_RETENTION_DAYS * 24 * 3600  # 30å¤©

# æ¸…ç†é—´éš”ï¼ˆç§’ï¼‰
CLEANUP_INTERVAL = 6 * 3600  # æ¯6å°æ—¶æ¸…ç†ä¸€æ¬¡

app.config['MAX_CONTENT_LENGTH'] = MAX_CONTENT_LENGTH

# ç¡®ä¿ç›®å½•å­˜åœ¨
for folder in [DATA_FOLDER, ORIGINALS_FOLDER, FRAMES_FOLDER, GIFS_FOLDER, TEMP_FOLDER]:
    os.makedirs(folder, exist_ok=True)


# ============================================
# è¾…åŠ©å‡½æ•°
# ============================================

def allowed_file(filename):
    """æ£€æŸ¥æ–‡ä»¶æ‰©å±•åæ˜¯å¦å…è®¸"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


def get_file_ext(filename):
    """è·å–æ–‡ä»¶æ‰©å±•å"""
    return filename.rsplit('.', 1)[1].lower() if '.' in filename else 'jpg'


def generate_task_id():
    """ç”Ÿæˆä»»åŠ¡IDï¼ˆåŸºäºæ—¶é—´æˆ³+UUIDï¼‰"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    short_uuid = str(uuid.uuid4())[:8]
    return f"{timestamp}_{short_uuid}"


def save_metadata(task_id, metadata):
    """ä¿å­˜ä»»åŠ¡å…ƒæ•°æ®"""
    meta_path = os.path.join(DATA_FOLDER, f"{task_id}_meta.json")
    with open(meta_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)


def cleanup_old_files():
    """æ¸…ç†è¿‡æœŸæ–‡ä»¶"""
    now = time.time()
    cleaned_count = 0
    
    # æ¸…ç†å„ä¸ªç›®å½•
    for folder in [ORIGINALS_FOLDER, FRAMES_FOLDER, GIFS_FOLDER, TEMP_FOLDER]:
        if not os.path.exists(folder):
            continue
            
        for item in os.listdir(folder):
            item_path = os.path.join(folder, item)
            try:
                item_time = os.path.getmtime(item_path)
                if now - item_time > FILE_MAX_AGE:
                    if os.path.isfile(item_path):
                        os.remove(item_path)
                    elif os.path.isdir(item_path):
                        shutil.rmtree(item_path)
                    cleaned_count += 1
            except Exception as e:
                print(f"[æ¸…ç†] åˆ é™¤å¤±è´¥: {item_path}, é”™è¯¯: {e}")
    
    # æ¸…ç†å…ƒæ•°æ®æ–‡ä»¶
    for item in os.listdir(DATA_FOLDER):
        if item.endswith('_meta.json'):
            item_path = os.path.join(DATA_FOLDER, item)
            try:
                if now - os.path.getmtime(item_path) > FILE_MAX_AGE:
                    os.remove(item_path)
                    cleaned_count += 1
            except Exception:
                pass
    
    if cleaned_count > 0:
        print(f"[æ¸…ç†] å·²æ¸…ç† {cleaned_count} ä¸ªè¿‡æœŸæ–‡ä»¶/ç›®å½•")


def start_cleanup_thread():
    """å¯åŠ¨åå°æ¸…ç†çº¿ç¨‹"""
    def cleanup_loop():
        while True:
            time.sleep(CLEANUP_INTERVAL)
            print(f"[æ¸…ç†] å¼€å§‹æ¸…ç†è¶…è¿‡ {FILE_RETENTION_DAYS} å¤©çš„æ–‡ä»¶...")
            cleanup_old_files()
    
    thread = threading.Thread(target=cleanup_loop, daemon=True)
    thread.start()
    print(f"[æ¸…ç†] åå°æ¸…ç†çº¿ç¨‹å·²å¯åŠ¨ï¼Œä¿ç•™æœŸé™: {FILE_RETENTION_DAYS} å¤©")


# ============================================
# è·¯ç”±
# ============================================

@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('index.html')


@app.route('/api/idea', methods=['POST'])
def idea_to_plan():
    """è°ƒç”¨ Geminiï¼Œæ ¹æ®åˆ›æ„ç”Ÿæˆç²¾çµè¡¨è®¡åˆ’ã€‚"""

    data = request.get_json(silent=True) or {}
    idea = (data.get('idea') or data.get('prompt') or '').strip()
    style = (data.get('style') or '').strip() or None
    model = (data.get('model') or '').strip() or None
    temperature = data.get('temperature', 0.6)

    if not idea:
        return jsonify({'error': 'è¯·æä¾› idea å­—æ®µ'}), 400

    try:
        temperature_value = float(temperature)
    except (TypeError, ValueError):
        return jsonify({'error': 'temperature å‚æ•°æ ¼å¼ä¸æ­£ç¡®'}), 400

    task_id = generate_task_id()
    try:
        plan = generate_idea_plan(
            idea,
            style=style,
            model=model,
            temperature=temperature_value,
        )
    except Exception as exc:  # noqa: BLE001
        return jsonify({'error': f'ç”Ÿæˆè®¡åˆ’å¤±è´¥: {exc}'}), 500

    metadata = {
        'task_id': task_id,
        'idea': idea,
        'style': style,
        'model': model,
        'temperature': temperature_value,
        'idea_plan': plan,
        'create_time': datetime.now().isoformat(),
    }
    save_metadata(task_id, metadata)

    return jsonify({
        'success': True,
        'task_id': task_id,
        'plan': plan,
    })


@app.route('/api/analyze', methods=['POST'])
def analyze():
    """åˆ†æä¸Šä¼ çš„å›¾ç‰‡ï¼Œè¿”å›ç½‘æ ¼æ£€æµ‹ç»“æœ"""
    if 'file' not in request.files:
        return jsonify({'error': 'æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶'}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400
    
    if not allowed_file(file.filename):
        return jsonify({'error': 'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼'}), 400
    
    try:
        # ç”Ÿæˆä»»åŠ¡ID
        task_id = generate_task_id()
        
        # è¯»å–å›¾ç‰‡æ•°æ®
        image_data = file.read()
        
        # ä¿å­˜åŸå›¾
        original_filename = secure_filename(file.filename) or f"image.{get_file_ext(file.filename)}"
        ext = get_file_ext(original_filename)
        original_path = os.path.join(ORIGINALS_FOLDER, f"{task_id}.{ext}")
        with open(original_path, 'wb') as f:
            f.write(image_data)
        
        # åˆ†æå›¾ç‰‡
        result = analyze_spritesheet(image_data)
        
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºåç»­è½¬æ¢ï¼‰
        temp_path = os.path.join(TEMP_FOLDER, f"{task_id}.tmp")
        with open(temp_path, 'wb') as f:
            f.write(image_data)
        
        # ä¿å­˜å…ƒæ•°æ®
        metadata = {
            'task_id': task_id,
            'original_filename': original_filename,
            'original_path': original_path,
            'upload_time': datetime.now().isoformat(),
            'analysis': result
        }
        save_metadata(task_id, metadata)
        
        return jsonify({
            'success': True,
            'file_id': task_id,
            'analysis': {
                'rows': result['rows'],
                'cols': result['cols'],
                'margin': result['margin'],
                'line_width': result['line_width'],
                'confidence': result['confidence'],
                'image_size': result['image_size'],
                'total_frames': result['rows'] * result['cols']
            }
        })
    
    except Exception as e:
        return jsonify({'error': f'åˆ†æå¤±è´¥: {str(e)}'}), 500


@app.route('/api/convert', methods=['POST'])
def convert():
    """å°†ç²¾çµè¡¨è½¬æ¢ä¸º GIF"""
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'æ— æ•ˆçš„è¯·æ±‚æ•°æ®'}), 400
    
    task_id = data.get('file_id')
    rows = data.get('rows')
    cols = data.get('cols')
    margin = data.get('margin', 2)
    duration = data.get('duration', 80)
    
    if not all([task_id, rows, cols]):
        return jsonify({'error': 'ç¼ºå°‘å¿…è¦å‚æ•°'}), 400
    
    temp_path = os.path.join(TEMP_FOLDER, f"{task_id}.tmp")
    
    if not os.path.exists(temp_path):
        return jsonify({'error': 'æ–‡ä»¶å·²è¿‡æœŸï¼Œè¯·é‡æ–°ä¸Šä¼ '}), 404
    
    try:
        # åˆ›å»ºå¸§ç›®å½•
        frames_dir = os.path.join(FRAMES_FOLDER, task_id)
        os.makedirs(frames_dir, exist_ok=True)
        
        # åˆ‡ç‰‡å¹¶ä¿å­˜å¸§æ–‡ä»¶
        saved_frames = slice_spritesheet(temp_path, frames_dir, rows, cols, margin)
        
        # ä»ä¿å­˜çš„å¸§ç”Ÿæˆ GIF
        frames = slice_spritesheet_to_frames(temp_path, rows, cols, margin)
        gif_data = create_gif_from_frames(frames, duration)
        
        # ä¿å­˜ GIF
        gif_path = os.path.join(GIFS_FOLDER, f"{task_id}.gif")
        with open(gif_path, 'wb') as f:
            f.write(gif_data)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            os.remove(temp_path)
        except Exception:
            pass
        
        # æ›´æ–°å…ƒæ•°æ®
        meta_path = os.path.join(DATA_FOLDER, f"{task_id}_meta.json")
        if os.path.exists(meta_path):
            with open(meta_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            metadata.update({
                'frames_dir': frames_dir,
                'frames_count': len(saved_frames),
                'gif_path': gif_path,
                'convert_time': datetime.now().isoformat(),
                'params': {
                    'rows': rows,
                    'cols': cols,
                    'margin': margin,
                    'duration': duration
                }
            })
            save_metadata(task_id, metadata)
        
        return jsonify({
            'success': True,
            'gif_id': task_id,
            'download_url': f'/api/download/{task_id}',
            'frames_count': len(saved_frames)
        })
    
    except Exception as e:
        return jsonify({'error': f'è½¬æ¢å¤±è´¥: {str(e)}'}), 500


@app.route('/api/download/<task_id>')
def download(task_id):
    """ä¸‹è½½ç”Ÿæˆçš„ GIF"""
    # å®‰å…¨æ£€æŸ¥
    if not task_id.replace('-', '').replace('_', '').isalnum():
        return jsonify({'error': 'æ— æ•ˆçš„æ–‡ä»¶ID'}), 400
    
    gif_path = os.path.join(GIFS_FOLDER, f"{task_id}.gif")
    
    if not os.path.exists(gif_path):
        return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ'}), 404
    
    return send_file(
        gif_path,
        mimetype='image/gif',
        as_attachment=True,
        download_name='sprite_animation.gif'
    )


@app.route('/api/preview/<task_id>')
def preview(task_id):
    """é¢„è§ˆç”Ÿæˆçš„ GIF"""
    if not task_id.replace('-', '').replace('_', '').isalnum():
        return jsonify({'error': 'æ— æ•ˆçš„æ–‡ä»¶ID'}), 400
    
    gif_path = os.path.join(GIFS_FOLDER, f"{task_id}.gif")
    
    if not os.path.exists(gif_path):
        return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ'}), 404
    
    return send_file(gif_path, mimetype='image/gif')


@app.route('/api/stats')
def stats():
    """è·å–å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯ï¼ˆç®¡ç†ç”¨ï¼‰"""
    def get_folder_stats(folder):
        if not os.path.exists(folder):
            return {'count': 0, 'size': 0}
        
        count = 0
        size = 0
        for item in os.listdir(folder):
            item_path = os.path.join(folder, item)
            if os.path.isfile(item_path):
                count += 1
                size += os.path.getsize(item_path)
            elif os.path.isdir(item_path):
                count += 1
                for root, dirs, files in os.walk(item_path):
                    for f in files:
                        size += os.path.getsize(os.path.join(root, f))
        return {'count': count, 'size': size}
    
    return jsonify({
        'retention_days': FILE_RETENTION_DAYS,
        'originals': get_folder_stats(ORIGINALS_FOLDER),
        'frames': get_folder_stats(FRAMES_FOLDER),
        'gifs': get_folder_stats(GIFS_FOLDER),
        'temp': get_folder_stats(TEMP_FOLDER)
    })


# ============================================
# å¯åŠ¨
# ============================================

# å¯åŠ¨æ—¶æ¸…ç†æ—§æ–‡ä»¶
cleanup_old_files()


if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('-p', '--port', type=int, default=8080, help='æœåŠ¡ç«¯å£')
    parser.add_argument('--data-dir', type=str, help='æ•°æ®å­˜å‚¨ç›®å½•')
    args = parser.parse_args()
    
    if args.data_dir:
        DATA_FOLDER = args.data_dir
        ORIGINALS_FOLDER = os.path.join(DATA_FOLDER, 'originals')
        FRAMES_FOLDER = os.path.join(DATA_FOLDER, 'frames')
        GIFS_FOLDER = os.path.join(DATA_FOLDER, 'gifs')
        TEMP_FOLDER = os.path.join(DATA_FOLDER, 'temp')
        for folder in [DATA_FOLDER, ORIGINALS_FOLDER, FRAMES_FOLDER, GIFS_FOLDER, TEMP_FOLDER]:
            os.makedirs(folder, exist_ok=True)
    
    # å¯åŠ¨åå°æ¸…ç†çº¿ç¨‹
    start_cleanup_thread()
    
    # è¿è¡ŒæœåŠ¡å™¨
    print(f"\nğŸš€ æœåŠ¡å·²å¯åŠ¨: http://localhost:{args.port}")
    print(f"ğŸ“ æ•°æ®ç›®å½•: {DATA_FOLDER}")
    print(f"ğŸ“… æ–‡ä»¶ä¿ç•™: {FILE_RETENTION_DAYS} å¤©\n")
    app.run(host='0.0.0.0', port=args.port, debug=False)
